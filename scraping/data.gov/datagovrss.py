#!/usr/bin/env python

# Copyright (c) 2009, James Turk, Sunlight Labs
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without modification,
# are permitted provided that the following conditions are met:
#
# * Redistributions of source code must retain the above copyright notice,
# this list of conditions and the following disclaimer.
# * Redistributions in binary form must reproduce the above copyright notice,
# this list of conditions and the following disclaimer in the documentation
# and/or other materials provided with the distribution.
# * Neither the name of James Turk, Sunlight Foundation, Sunlight Labs
# nor the names of its contributors may be used to endorse or promote products
# derived from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY
# EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL
# THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
# OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
# STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
# OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

"""
    Dependencies:
        python 2.5
        sqlite3
        lxml
        PyRSS2Gen
"""

import sqlite3

def scrape_catalog():
    import urllib2
    from lxml.html import parse

    doc = parse(urllib2.urlopen('http://www.data.gov/catalog'))
    rows = doc.getroot().cssselect('tbody tr')

    for row in rows:
        a = row.cssselect('div.name a')[0]
        id = a.attrib['href'].replace('/details/', '')
        title = a.text_content()
        teaser = row.cssselect('span.teaser')[0].text_content()
        yield {'id':id, 'title':title, 'teaser':teaser}


#'CREATE TABLE datagov_dataitems (id INTEGER, title TEXT, teaser TEXT, first_seen INTEGER)'

def update_db(data, database):
    import time
    db = sqlite3.connect(database)

    for row in data:
        num = db.execute('SELECT COUNT(id) FROM datagov_dataitems WHERE id=?', (row['id'],)).fetchone()[0]
        if not num:
            print 'inserting', row['title']
            db.execute('INSERT INTO datagov_dataitems (id, title, teaser, first_seen) VALUES (?,?,?,?)',
                        (row['id'], row['title'], row['teaser'], int(time.time())))
    db.commit()

def write_rss(data, filename):
    import datetime
    import PyRSS2Gen

    rssitems = []
    for item in data:
        url = 'http://www.data.gov/details/%s/' % item['id']
        rssitems.append(PyRSS2Gen.RSSItem(
            title=item['title'], link=url, description=item['teaser'],
            guid=PyRSS2Gen.Guid(url),
            pubDate=datetime.datetime.fromtimestamp(item['first_seen'])))

    rss = PyRSS2Gen.RSS2(
        title = 'Unofficial Data.gov feed',
        link = '--fixme--',
        description = 'Unofficial feed of all data in the Data.gov catalog generated by Sunlight Labs',
        lastBuildDate = datetime.datetime.now(),
        items = rssitems)

    rss.write_xml(open(filename,'w'))

DB_NAME = 'cache.db'
if __name__ == '__main__':
    update_db(scrape_catalog(), DB_NAME)
    db = sqlite3.connect(DB_NAME)
    db.row_factory = sqlite3.Row
    rows = db.execute('SELECT id, title, teaser, first_seen FROM datagov_dataitems ORDER BY first_seen DESC').fetchall()
    write_rss(rows, 'output.xml')
